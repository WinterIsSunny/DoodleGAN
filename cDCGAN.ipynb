{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Reshape, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, Conv2D, Conv2DTranspose\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import cifar10\n",
    "import keras.backend as K\n",
    "from keras.preprocessing import image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matplotlib.interactive(True)\n",
    "\n",
    "channels = 1\n",
    "img_size = 28\n",
    "img_w = img_h = img_size\n",
    "img_shape = (img_size, img_size, channels)\n",
    "n_epochs = 200\n",
    "\n",
    "classes = ['saxophone',\n",
    "    'raccoon',\n",
    "    'piano',\n",
    "    'panda',\n",
    "    'leg',\n",
    "    'headphones',\n",
    "    'ceiling_fan',\n",
    "    'bed',\n",
    "    'basket',\n",
    "    'aircraft_carrier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fa9a05de9f82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mnoise_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgen_condition_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Input' is not defined"
     ]
    }
   ],
   "source": [
    "# Generator\n",
    "def get_generator(input_layer, condition_layer):\n",
    "  \n",
    "  merged_input = Concatenate()([input_layer, condition_layer])  \n",
    "  \n",
    "  dense1 = Dense(128 * 8 * 8, activation='relu')(merged_input)    \n",
    "  desen1 = BatchNormalization(momentum=0.9)(desen1)\n",
    "  desen1 = LeakyReLU(alpha=0.1)(desen1)\n",
    "  desen1 = Reshape((8, 8, 128))(desen1)\n",
    "  \n",
    "  conv1 = Conv2D(128, kernel_size=4, strides=1,padding='same')(desen1)\n",
    "  conv1 = BatchNormalization(momentum=0.9)(conv1)    \n",
    "  conv1 = LeakyReLU(alpha=0.1)(conv1)\n",
    "  \n",
    "  conv2 = Conv2DTranspose(128, 4, strides=2, padding='same')(conv1)\n",
    "  conv2 = BatchNormalization(momentum=0.9)(conv2)\n",
    "  conv2 = LeakyReLU(alpha=0.1)(conv2)\n",
    "  \n",
    "  conv3 = Conv2D(128, kernel_size=5, strides=1,padding='same')(conv2)\n",
    "  conv3 = BatchNormalization(momentum=0.9)(conv3)    \n",
    "  conv3 = LeakyReLU(alpha=0.1)(conv3)\n",
    "  \n",
    "  conv4 = Conv2DTranspose(128, 4, strides=2, padding='same')(conv3)\n",
    "  conv4 = BatchNormalization(momentum=0.9)(conv4)\n",
    "  conv4 = LeakyReLU(alpha=0.1)(conv4)\n",
    "  \n",
    "  conv5 = Conv2D(128, kernel_size=5, strides=1, padding='same')(conv4)\n",
    "  conv5 = BatchNormalization(momentum=0.9)(conv5)\n",
    "  conv5 = LeakyReLU(alpha=0.1)(conv5)\n",
    "  \n",
    "  conv6 = Conv2D(128, kernel_size=5, strides=1, padding='same')(conv5)\n",
    "  conv6 = BatchNormalization(momentum=0.9)(conv6)\n",
    "  conv6 = LeakyReLU(alpha=0.1)(conv6)\n",
    "                      \n",
    "  output = Conv2D(1, kernel_size=5, strides=1, padding=\"same\")(conv6)\n",
    "  out = Activation(\"tanh\")(output)\n",
    "  model = Model(inputs=[input_layer, condition_layer], outputs=out)\n",
    "  model.summary()\n",
    "  \n",
    "  return model, out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# discriminator \n",
    "def get_discriminator(input_layer, condition_layer):\n",
    "  \n",
    "  conv1 = Conv2D(128, kernel_size=3, strides=1, padding='same')(input_layer)\n",
    "  conv1 = BatchNormalization(momentum=0.9)(conv1)\n",
    "  conv1 = LeakyReLU(alpha=0.1)(conv1)\n",
    "  \n",
    "  conv2 = Conv2D(128, kernel_size=4, strides=2, padding='same')(conv1)\n",
    "  conv2 = BatchNormalization(momentum=0.9)(conv2)\n",
    "  conv2 = LeakyReLU(alpha=0.1)(conv2)\n",
    "  \n",
    "  conv3 = Conv2D(128, kernel_size=4, strides=2, padding='same')(conv2)\n",
    "  conv3 = BatchNormalization(momentum=0.9)(conv3)\n",
    "  conv3 = LeakyReLU(alpha=0.1)(conv3)\n",
    "  \n",
    "  conv4 = Conv2D(128, kernel_size=4, strides=2, padding='same')(conv3)\n",
    "  conv4 = BatchNormalization(momentum=0.9)(conv4)\n",
    "  conv4 = LeakyReLU(alpha=0.1)(conv4)\n",
    "  conv4 = Flatten()(conv4)\n",
    "  \n",
    "  merged_layer = Concatenate()([conv4, condition_layer])\n",
    "  output = Dense(512, activation='relu')(merged_layer)\n",
    "  #hid = Dropout(0.4)(hid)\n",
    "  out = Dense(1, activation='sigmoid')(output)\n",
    "  model = Model(inputs=[input_layer, condition_layer], outputs=out)\n",
    "  model.summary()\n",
    "  \n",
    "  return model, out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(y):\n",
    "  z = np.zeros((len(y), 10))\n",
    "  idx = np.arange(len(y))\n",
    "  z[idx, y] = 1\n",
    "  return z\n",
    "\n",
    "def generate_noise(n_samples, noise_dim):\n",
    "  X = np.random.normal(0, 1, size=(n_samples, noise_dim))\n",
    "  return X\n",
    "\n",
    "def generate_random_labels(n):\n",
    "  y = np.random.choice(10, n)\n",
    "  y = one_hot_encode(y)\n",
    "  return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_input = Input(shape=(32,32,3))\n",
    "disc_condition_input = Input(shape=(10,))\n",
    "discriminator, disc_out = get_discriminator(img_input, disc_condition_input)\n",
    "discriminator.trainable = False\n",
    "\n",
    "noise_input = Input(shape=(100,))\n",
    "gen_condition_input = Input(shape=(10,))\n",
    "generator, gen_out = get_generator(noise_input, gen_condition_input)\n",
    "\n",
    "gan_input = Input(shape=(100,))\n",
    "x = generator([gan_input, gen_condition_input])\n",
    "gan_out = discriminator([x, disc_condition_input])\n",
    "AM = Model(inputs=[gan_input, gen_condition_input, disc_condition_input], output=gan_out)\n",
    "AM.summary()\n",
    "AM.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(df, epochs=20,batch=128):\n",
    "    d_loss = []\n",
    "    a_loss = []\n",
    "    running_d_loss = 0\n",
    "    running_d_acc = 0\n",
    "    running_a_loss = 0\n",
    "    running_a_acc = 0\n",
    "    for i in range(1, epochs+1):\n",
    "        batch_idx = np.random.choice(df.shape[0] ,batch,replace=False)\n",
    "\n",
    "        real_imgs = np.array([np.reshape(row, (28, 28, 1)) for row in df['Image'].iloc[batch_idx]])\n",
    "        real_labels = np.array(df['Label'].iloc[batch_idx])\n",
    "        \n",
    "        noise_data = generator_noise(batch,100)\n",
    "        random_labels = generate_random_labels(batch)\n",
    "        fake_imgs = generator.predict([noise_data, labels])\n",
    "        \n",
    "        # Train on soft targets (add noise to targets as well)\n",
    "        noise_prop = 0.05 # Randomly flip 5% of targets\n",
    "        \n",
    "        # Prepare labels for real data\n",
    "        true_labels = np.zeros((batch, 1)) + np.random.uniform(low=0.0, high=0.1, size=(batch, 1))\n",
    "        flipped_idx = np.random.choice(np.arange(len(true_labels)), size=int(noise_prop*len(true_labels)))\n",
    "        true_labels[flipped_idx] = 1 - true_labels[flipped_idx]\n",
    "        # Train discriminator on real data\n",
    "        make_trainable(discriminator, True)\n",
    "        d_loss_true = discriminator.train_on_batch([images, labels], true_labels)\n",
    "        \n",
    "        # Prepare labels for generated data\n",
    "        gene_labels = np.ones((batch, 1)) - np.random.uniform(low=0.0, high=0.1, size=(batch, 1))\n",
    "        flipped_idx = np.random.choice(np.arange(len(gene_labels)), size=int(noise_prop*len(gene_labels)))\n",
    "        gene_labels[flipped_idx] = 1 - gene_labels[flipped_idx]\n",
    "        \n",
    "        # Train discriminator on generated data\n",
    "        d_loss_gene = discriminator.train_on_batch([generated_images, labels], gene_labels)\n",
    "        d_loss.append(0.5 * np.add(d_loss_true, d_loss_gene))\n",
    "        running_d_loss += d_loss[-1][0]\n",
    "        running_d_acc += d_loss[-1][1]\n",
    "        make_trainable(discriminator, False)\n",
    "        \n",
    "        # Train generator\n",
    "        noise_data = generate_noise(batch, 100)\n",
    "        random_labels = generate_random_labels(batch)\n",
    "        g_loss = AM.train_on_batch([noise_data, random_labels, random_labels], np.zeros((batch, 1)))\n",
    "        a_loss.append(g_loss)\n",
    "        running_a_loss += a_loss[-1][0]\n",
    "        running_a_acc += a_loss[-1][1]\n",
    "    \n",
    "        log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, running_d_loss/i, running_d_acc/i)\n",
    "        log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, running_a_loss/i, running_a_acc/i)\n",
    "        print(log_mesg)\n",
    "        \n",
    "        noise_data = generate_noise(batch, 100)\n",
    "        random_labels = generate_random_labels(batch)\n",
    "        # We use same labels for generated images as in the real training batch\n",
    "        gen_imgs = generator.predict([noise_data, labels])\n",
    "        plt.figure(figsize=(5,5))\n",
    "        for k in range(gen_imgs.shape[0]):\n",
    "            plt.subplot(4, 4, k+1)\n",
    "            plt.imshow(gen_imgs[k, :, :, 0], cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.savefig('./images/{}.png'.format(i+1))\n",
    "    return a_loss, d_loss\n",
    "\n",
    "def get_all_classes():\n",
    "    df = pd.DataFrame([], columns=['Image', 'Label'])\n",
    "    for i, label in enumerate(classes):\n",
    "        data = np.load('./data/%s.npy' % label) / 255\n",
    "        data = np.reshape(data, [data.shape[0], img_size, img_size, 1])\n",
    "        df2 = pd.DataFrame([(row, i) for row in data], columns=['Image', 'Label'])\n",
    "        df = df.append(df2)\n",
    "    return df.sample(frac=1) # shuffle\n",
    "\n",
    "def save_model(model_json, name):\n",
    "    with open(name, \"w+\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "def save_real_imgs(real_imgs):\n",
    "    doodle_per_img = 16\n",
    "    for i in range(real_imgs.shape[0] - doodle_per_img):\n",
    "        plt.figure(figsize=(5,5))\n",
    "        for k in range(doodle_per_img):\n",
    "            plt.subplot(4, 4, k+1)\n",
    "            plt.imshow(real_imgs.iloc[i + k].reshape((img_size, img_size)), cmap='gray')\n",
    "            plt.axis('off')\n",
    "        print(\"Saving {}\".format(i))\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.savefig('./images/real_{}.png'.format(i+1))\n",
    "        \n",
    "def make_trainable(net, is_trainable):\n",
    "    net.trainable = is_trainable\n",
    "    for l in net.layers:\n",
    "        l.trainable = is_trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = get_all_classes()\n",
    "data['Label'] = one_hot_encode(data['Label'][:,0])\n",
    "train(data, epochs=n_epochs, batch=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model(generator.to_json(), \"generator.json\")\n",
    "save_model(AM.to_json(), \"discriminator.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
